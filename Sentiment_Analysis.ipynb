{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMUb8YnhEKxt0O+3xYmZ3f6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narsym/deep-learning-with-tensorflow-2.0/blob/master/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br0KPc5mUrOf",
        "colab_type": "text"
      },
      "source": [
        "#Many to one "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuhSi5zDVWAC",
        "colab_type": "text"
      },
      "source": [
        "Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0ra8rxUVYU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP9MT2A1VlEh",
        "colab_type": "text"
      },
      "source": [
        "download and read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqAV3gEWVtWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_and_read(url):\n",
        "    local_file = url.split('/')[-1]\n",
        "    local_file = local_file.replace(\"%20\", \" \")\n",
        "    p = tf.keras.utils.get_file(local_file, url, \n",
        "        extract=True, cache_dir=\".\")\n",
        "    local_folder = os.path.join(\"datasets\", local_file.split('.')[0])\n",
        "    labeled_sentences = []\n",
        "    for labeled_filename in os.listdir(local_folder):\n",
        "        if labeled_filename.endswith(\"_labelled.txt\"):\n",
        "            with open(os.path.join(local_folder, labeled_filename), \"r\") as f:\n",
        "                for line in f:\n",
        "                    sentence, label = line.strip().split('\\t')\n",
        "                    labeled_sentences.append((sentence, label))\n",
        "    return labeled_sentences\n",
        "\n",
        "labeled_sentences = download_and_read(\n",
        "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip\")\n",
        "sentences = [s for (s, l) in labeled_sentences]\n",
        "labels = [int(l) for (s, l) in labeled_sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZuH8CfwXpck",
        "colab_type": "text"
      },
      "source": [
        "Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTdmMpljZDn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a09fa9c-792d-4d03-8821-405031140c3c"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "vocab_size = len(tokenizer.word_counts)\n",
        "print(f'vocabulary size: {vocab_size}')\n",
        "\n",
        "word2idx = tokenizer.word_index\n",
        "idx2word = {v:k for (k, v) in word2idx.items()}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocabulary size: 5271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfjXPUdSZsvT",
        "colab_type": "text"
      },
      "source": [
        "Fixing maximum sequence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q5shVegegLX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7110f2f7-a302-421c-9ff7-ef27b6a45ea6"
      },
      "source": [
        "seq_length = np.array([len(s.split()) for s in sentences])\n",
        "print([(p, np.percentile(seq_length, p)) for p in [75, 80, 90, 95, 99, 100]])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(75, 16.0), (80, 18.0), (90, 22.0), (95, 26.0), (99, 36.0), (100, 71.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrL-qKBoe3gg",
        "colab_type": "text"
      },
      "source": [
        "99% of the sentences are under 36.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52gEKbhFfPzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seqlen = 64\n",
        "sentences_as_ints = tokenizer.texts_to_sequences(sentences)\n",
        "sentences_as_ints = tf.keras.preprocessing.sequence.pad_sequences(sentences_as_ints, maxlen = max_seqlen)\n",
        "labels_as_ints = np.array(labels)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((sentences_as_ints, labels_as_ints))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxePnhb3hXJ3",
        "colab_type": "text"
      },
      "source": [
        "Train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HfeS9_5hwbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.shuffle(10000)\n",
        "test_size = len(sentences) // 3\n",
        "val_size = (len(sentences) - test_size) // 10\n",
        "test_dataset = dataset.take(test_size)\n",
        "val_dataset = dataset.skip(test_size).take(val_size)\n",
        "train_dataset = dataset.skip(val_size + test_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKGcPgnSiSL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JortceRRi2c8",
        "colab_type": "text"
      },
      "source": [
        "Chapter 8[ 303 ]Next we define our model. As you can see, the model is fairly straightforward, each input sentence is a sequence of integers of size max_seqlen (64). This is input into an Embedding layer that converts each word into a vector given by the size of the vocabulary + 1. The additional word is to account for the padding integer 0 that was introduced during the pad_sequences() call above. The vector at each of the 64 time steps are then fed into a bidirectional LSTM layer, which coverts each word to a vector of size (64,). The output of the LSTM at each time step is fed into a Dense layer, which produces a vector of size (64,) with ReLU activation. The output of this Dense layer is then fed into another Dense layer, which outputs a vector of (1,) at each time step, modulated through a sigmoid activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0jsVywelB4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "58e6f0f7-7007-483d-ada5-9716497367cf"
      },
      "source": [
        "class SentimentAnalysisModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, max_seqlen, **kwargs):\n",
        "        super(SentimentAnalysisModel, self).__init__(**kwargs)\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, max_seqlen)\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(max_seqlen)\n",
        "        )\n",
        "        self.dense = tf.keras.layers.Dense(64, activation=\"relu\")\n",
        "        self.out = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.bilstm(x)\n",
        "        x = self.dense(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "model = SentimentAnalysisModel(vocab_size + 1, max_seqlen)\n",
        "model.build(input_shape = (batch_size, max_seqlen))#send input shape as parameter always, for model subclassing\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sentiment_analysis_model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      multiple                  337408    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection multiple                  66048     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  65        \n",
            "=================================================================\n",
            "Total params: 411,777\n",
            "Trainable params: 411,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErsdO_a3mu-c",
        "colab_type": "text"
      },
      "source": [
        "compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aw8W9RwnLFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7yubz0RnWO4",
        "colab_type": "text"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og9EK3jQnYLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "f75b7802-215f-4c9f-a752-c5606e0f974a"
      },
      "source": [
        "data_dir = './data'\n",
        "logs_dir = os.path.join('./logs')\n",
        "best_model_file = os.path.join(data_dir, 'best_model.h5')\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(best_model_file, save_weights_only = True, save_best_only = True)\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(logs_dir)\n",
        "num_epochs = 10\n",
        "history = model.fit(train_dataset, epochs = num_epochs, validation_data = val_dataset, callbacks = [checkpoint, tensorboard])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "29/29 [==============================] - 3s 120ms/step - loss: 0.6908 - accuracy: 0.5378 - val_loss: 0.6777 - val_accuracy: 0.6650\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.5954 - accuracy: 0.7422 - val_loss: 0.4657 - val_accuracy: 0.8450\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 3s 89ms/step - loss: 0.3498 - accuracy: 0.8578 - val_loss: 0.2667 - val_accuracy: 0.8850\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 3s 90ms/step - loss: 0.2229 - accuracy: 0.9206 - val_loss: 0.2200 - val_accuracy: 0.9250\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 3s 90ms/step - loss: 0.1289 - accuracy: 0.9639 - val_loss: 0.1710 - val_accuracy: 0.9700\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 3s 89ms/step - loss: 0.1125 - accuracy: 0.9694 - val_loss: 0.1030 - val_accuracy: 0.9750\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.0921 - accuracy: 0.9772 - val_loss: 0.0843 - val_accuracy: 0.9800\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 3s 89ms/step - loss: 0.0706 - accuracy: 0.9817 - val_loss: 0.0545 - val_accuracy: 0.9850\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.0530 - accuracy: 0.9867 - val_loss: 0.0141 - val_accuracy: 0.9950\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.0484 - accuracy: 0.9872 - val_loss: 0.0167 - val_accuracy: 0.9950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56LpKNCKpRGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = SentimentAnalysisModel(vocab_size + 1, max_seqlen)\n",
        "best_model.build(input_shape = (batch_size, max_seqlen))\n",
        "best_model.load_weights(best_model_file)\n",
        "best_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgQXMeHHp9dF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a2ce0479-94ea-4b76-b2e6-194c7d39fa61"
      },
      "source": [
        "test_loss, test_accuracy = best_model.evaluate(test_dataset)\n",
        "print(f'test_loss: {test_loss}, test_accuracy: {test_accuracy}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0326 - accuracy: 0.9940\n",
            "test_loss: 0.032562725245952606, test_accuracy: 0.9940000176429749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNAt1azDqQiv",
        "colab_type": "text"
      },
      "source": [
        "Prediction manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HedXutaYqb2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "a48b8bc7-7a6a-4fc6-9305-a08cb35a3f1e"
      },
      "source": [
        "# predict on batches\n",
        "labels, predictions = [], []\n",
        "idx2word[0] = \"PAD\"\n",
        "is_first_batch = True\n",
        "for test_batch in test_dataset:\n",
        "    inputs_b, labels_b = test_batch\n",
        "    pred_batch = best_model.predict(inputs_b)\n",
        "    predictions.extend([(1 if p > 0.5 else 0) for p in pred_batch])\n",
        "    labels.extend([l for l in labels_b])\n",
        "    if is_first_batch:\n",
        "        for rid in range(inputs_b.shape[0]):\n",
        "            words = [idx2word[idx] for idx in inputs_b[rid].numpy()]\n",
        "            words = [w for w in words if w != \"PAD\"]\n",
        "            sentence = \" \".join(words)\n",
        "        is_first_batch = False\n",
        "\n",
        "print(\"accuracy score: {:.3f}\".format(accuracy_score(labels, predictions)))\n",
        "print(\"confusion matrix\")\n",
        "print(confusion_matrix(labels, predictions))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score: 0.990\n",
            "confusion matrix\n",
            "[[485   4]\n",
            " [  6 505]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T5CxkmqqjFq",
        "colab_type": "text"
      },
      "source": [
        "We got 99% accuracy"
      ]
    }
  ]
}